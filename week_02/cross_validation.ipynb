{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828cbd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b791a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_path: str):\n",
    "    # Load the data\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Handle categorical features\n",
    "    categorical_features = [x for x in df.columns if df[x].dtype == 'object']\n",
    "    \n",
    "    # Split the data\n",
    "    features = df.columns.drop(\"price\")\n",
    "    target = \"price\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], train_size=0.85, test_size=0.15, random_state=1234)\n",
    "    \n",
    "    # One Hot Encoding\n",
    "    ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    ohe.fit(X_train[categorical_features])\n",
    "    \n",
    "    def apply_ohe(ohe: OneHotEncoder, X: pd.DataFrame, cat_features: list):\n",
    "        encoded_array = ohe.transform(X[cat_features])\n",
    "        encoded_df = pd.DataFrame(\n",
    "            encoded_array, \n",
    "            columns=ohe.get_feature_names_out(cat_features)\n",
    "        )\n",
    "        X.drop(columns=cat_features, inplace=True)\n",
    "        X = pd.concat(\n",
    "            [\n",
    "                X.reset_index(drop=True), \n",
    "                encoded_df.reset_index(drop=True)\n",
    "            ], \n",
    "            axis=1\n",
    "        )\n",
    "        return X\n",
    "    \n",
    "    X_train = apply_ohe(ohe, X_train.copy(), categorical_features)\n",
    "    X_test = apply_ohe(ohe, X_test.copy(), categorical_features)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacdd05c",
   "metadata": {},
   "source": [
    "#### Cross-Validation Example for House Pricing Model\n",
    "\n",
    "Notes:\n",
    "- Cross-validation is a statistical method used to estimate the performance of machine learning models.\n",
    "- It involves splitting the dataset into multiple subsets (folds) and training/testing the model on different combinations of these subsets.\n",
    "- This helps ensure that the model performs well on unseen data and reduces the risk of overfitting.\n",
    "\n",
    "Why Cross-Validation is Important:\n",
    "1. Provides a more reliable estimate of model performance compared to a single train-test split.\n",
    "2. Helps identify overfitting or underfitting issues.\n",
    "3. Ensures the model generalizes well to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab1fb992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores (RMSE): [1160388.30145678  925978.19039612 1055761.77560161 1139526.75245282\n",
      " 1154993.4021494 ]\n",
      "Mean RMSE: 1087329.6844113462\n",
      "Standard Deviation of RMSE: 89074.47627959249\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_and_preprocess_data(\"./data/Housing.csv\")\n",
    "\n",
    "# Initialize the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Perform cross-validation\n",
    "# Using 5-fold cross-validation\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "# Convert negative RMSE to positive RMSE\n",
    "# Explanation:\n",
    "# In scikit-learn, the scoring parameter for cross_val_score expects higher values to indicate better performance.\n",
    "# Since RMSE is a metric where lower values are better, it is negated during scoring to align with this convention.\n",
    "# By negating the RMSE scores, scikit-learn can rank models correctly during cross-validation.\n",
    "rmse_scores = -cv_scores\n",
    "\n",
    "# Print results\n",
    "print(\"Cross-Validation Scores (RMSE):\", rmse_scores)\n",
    "print(\"Mean RMSE:\", rmse_scores.mean())\n",
    "print(\"Standard Deviation of RMSE:\", rmse_scores.std())\n",
    "\n",
    "# Notes:\n",
    "# In this example, we used 5-fold cross-validation to evaluate the LinearRegression model.\n",
    "# The dataset was split into 5 folds, and the model was trained on 4 folds while being tested on the remaining fold.\n",
    "# This process was repeated 5 times, and the mean squared error (MSE) was calculated for each fold.\n",
    "# The mean and standard deviation of the MSE provide insights into the model's performance and stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3769c50",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro_ml_sjp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
